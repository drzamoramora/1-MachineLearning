{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesgo y Varianza en Modelos\n",
    "\n",
    "<font color=red>Definición 1.6</font> **Varianza** refiere a la cantidad de a la cual la función f(x) cambia si la hubiéramos estimado usando otro dataset. Esto quiere decir que si la forma de f(x) no cambia mucho si se usan otros datasets, entonces se dice que que tiene poca varianza.\n",
    "\n",
    "<font color=red>Definición 1.7</font> **Sesgo (bias)** refiere al error que introduce f(x) al aproximar los datos.\n",
    "\n",
    "<img src=\"img/bias-variance.png\" style=\"height:600px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genramos algunos datos\n",
    "\n",
    "X = np.array([0.01      , 0.01930698, 0.03727594, 0.07196857, 0.13894955,\n",
    "       0.26826958, 0.51794747, 1.])\n",
    "\n",
    "y = np.array([1.79111708, 1.81833914, 3.20477112, 5.30543043, 6.74879517,\n",
    "       6.79595893, 8.85678367, 9.01523049])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deplegamos los datos usando Matplotlib.\n",
    "\n",
    "plt.scatter(X,y, marker = \"x\", s = 60, c = \"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alto Sesgo - Baja Varianza\n",
    "\n",
    "Se dice que los datos y_prima fueron generados por una función f(x)' con diferente nivel de ajuste.\n",
    "\n",
    "<font color=red>Definición 1.8</font> El **ajuste** de una función está determinado por la relación sesgo-varianza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prima = np.array([ 3.7516687,   3.81511469,  3.93760973,  4.17411062,  4.63072235,  5.51230157,\n",
    "  7.21436459, 10.50053378])\n",
    "\n",
    "plt.scatter(X,y, marker = \"x\", s = 60, c = \"black\")\n",
    "plt.plot(X, y_prima, c = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste Perfecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prima = np.array([2.69521372, 2.89130589, 3.2624715,  3.95138743, 5.17824884, 7.16215907,\n",
    " 9.55815552, 8.83748405])\n",
    "\n",
    "plt.scatter(X,y, marker = \"x\", s = 60, c = \"black\")\n",
    "plt.plot(X, y_prima, c = \"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alta Varianza y Bajo Sesgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prima = np.array([1.69257086, 2.02072529, 3.06428013, 5.34757029, 6.74293985, 6.79633583,\n",
    " 8.85677319, 9.01523059])\n",
    "\n",
    "plt.scatter(X,y, marker = \"x\", s = 60, c = \"black\")\n",
    "plt.plot(X, y_prima, c = \"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretabilidad de Modelos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Definición 1.9</font> Un **Modelo** de ML  es el resultado del entrenamiento de un algoritmo *f(x)* de machine learning. Este resultado es utilizado para generar predicciones o inferencias. El modelo está compuesto por el algoritmo, la meta-data generada, parámetros, coeficientes e hiper-parámetros. \n",
    "\n",
    "Algunas preguntas para debatir:\n",
    "\n",
    "- ¿Son todos los modelos interpretables? (somos capaces de entender por que, el modelo hace la predicción de la forma en la que la hace?)\n",
    "- Qué importa si el modelo no es interpretable, mientras sirva... (es esto aceptable? cuando lo es, cuando no lo es?)\n",
    "- El concepto de interpretabilidad es un factor de peso de la existencia de las ramas de machine learning y statistical learning?\n",
    "- La interpretabilidad de modelos es clave para comprender la relación sesgo-varianza?\n",
    "- la función **real** f(x) muchas veces no está disponible, es un modelo aproximado suficiente?\n",
    "- Es machine learning no interpretable una caja negra?\n",
    "- ¿Da la interpretabilidad confianza en las capacidades del algoritmo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/int1.png\" style=\"width:900px\" />\n",
    "<img src=\"img/int2.png\" style=\"width:900px\" />\n",
    "<img src=\"img/int3.png\" style=\"width:900px\" />\n",
    "<img src=\"img/int4.png\" style=\"width:900px\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
